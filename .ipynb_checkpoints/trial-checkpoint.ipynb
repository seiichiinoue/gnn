{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GNN実装\n",
    "- PFN internの選考課題であるGNNのフルスクラッチ実装問題を解いてみる．\n",
    "\n",
    "## 課題1\n",
    "- GNNにおける集約とReadoutの関数を作れ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def aggregate(W, X):\n",
    "    A = [np.sum(X, axis=0) - X[i] for i in range(len(X))]\n",
    "    ret = [relu(np.dot(W, A[i])) for i in range(len(A))]\n",
    "    return np.array(ret)\n",
    "\n",
    "def readout(X):\n",
    "    return np.sum(X, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(t_hop, W, X):\n",
    "    X_t = X\n",
    "    for t in range(t_hop):\n",
    "        ag = aggregate(W, X_t)\n",
    "        X_t = ag\n",
    "    return readout(X_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### テスト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 4, 2])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([[0, 1, 1],\n",
    "              [1, 1, 0],\n",
    "              [1, 0, 0]])\n",
    "\n",
    "W = np.array([[-1, 0, 0],\n",
    "              [ 0, 1, 0],\n",
    "              [ 0, 0, 1]])\n",
    "\n",
    "# aggregate\n",
    "ag = aggregate(W, X)\n",
    "readout(ag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 4, 2])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forward(1, W, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 課題2\n",
    "- 課題1で求めた出力の重み付き和をとり，それを活性化関数にかけて確率値pを得る．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy(h, A, b, y):\n",
    "    s = np.dot(A, h) + b\n",
    "    p = 1. / (1. + np.exp(-s.astype(float)))\n",
    "    # avoid overflow\n",
    "    if s > 5:\n",
    "        L = y * np.log(1. + np.exp(-s.astype(float))) + (1-y) * np.log(1. + np.exp(s.astype(float)))\n",
    "    else:\n",
    "        L = -y * np.log(p) - (1-y) * np.log(1-p)\n",
    "    return L.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(t_hop, X, y, W, A, b, eps=0.001, alpha=0.0001):\n",
    "    \"\"\"\n",
    "    - minimize Loss on theta; W, A, b\n",
    "    \"\"\"\n",
    "    # For A\n",
    "    h = forward(t_hop, W, X)\n",
    "    A_deriv = []\n",
    "    for i in range(len(A)):\n",
    "        A_delta = A\n",
    "        A_delta[i] += eps\n",
    "        A_deriv.append((cross_entropy(h, A_delta, b, y) - cross_entropy(h, A, b, y))/eps)\n",
    "    # For b\n",
    "    b_deriv = (cross_entropy(h, A, b + eps, y) - cross_entropy(h, A, b, y))/eps\n",
    "    \n",
    "    \n",
    "    # For W\n",
    "    W_deriv = []\n",
    "    for i in range(len(W)):\n",
    "        temp = []\n",
    "        for j in range(len(W[i])):\n",
    "            W_delta = W\n",
    "            W_delta[i][j] += eps\n",
    "            temp.append((cross_entropy(forward(t_hop, W_delta, X), A, b, y) - cross_entropy(forward(t_hop, W, X), A, b, y))/eps)\n",
    "        W_deriv.append(temp)\n",
    "\n",
    "    # Update all parameters\n",
    "    A_new = A - np.dot(alpha, A_deriv)\n",
    "    b_new = b - alpha * b_deriv\n",
    "    W_new = W - np.dot(alpha, W_deriv)\n",
    "    \n",
    "    return np.array(A_new), np.array(b_new), np.array(W_new)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### テスト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test input\n",
    "X = [[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
    "    [1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
    "    [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
    "    [0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1],\n",
    "    [1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0]]\n",
    "y = 1\n",
    "\n",
    "# params init\n",
    "np.random.seed(10)\n",
    "A = np.random.normal(0, 0.4, 11)\n",
    "b = 0\n",
    "W = np.random.normal(0, 0.4, (11, 11))\n",
    "\n",
    "a_, b_, w_ = update(1, X, y, W, A, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GNN モデル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(69)\n",
    "\n",
    "class GNN(object):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.input_dim = len(X)\n",
    "        # initialize params\n",
    "        self.W = np.random.normal(0, 0.4, (self.input_dim, self.input_dim))\n",
    "        self.A = np.random.normal(0, 0.4, self.input_dim)\n",
    "        self.b = 0\n",
    "        \n",
    "        \n",
    "    def relu(self, x):\n",
    "        return np.maximum(0, x)\n",
    "\n",
    "    def aggregate(self, W, X):\n",
    "        A = [np.sum(X, axis=0) - X[i] for i in range(len(X))]\n",
    "        ret = [self.relu(np.dot(W, A[i])) for i in range(len(A))]\n",
    "        return np.array(ret)\n",
    "\n",
    "    def readout(self, X):\n",
    "        return np.sum(X, axis=0)\n",
    "    \n",
    "    def forward(self, t_hop, W, X):\n",
    "        \"\"\"\n",
    "        forward method.\n",
    "        \"\"\"\n",
    "        X_t = X\n",
    "        for t in range(t_hop):\n",
    "            ag = self.aggregate(W, X_t)\n",
    "            X_t = ag\n",
    "        return self.readout(X_t)\n",
    "    \n",
    "    def sigmoid(self, x):\n",
    "        if x < 0:\n",
    "            a = np.exp(x) \n",
    "            return a / (1 + a) \n",
    "        else:\n",
    "            return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    def cross_entropy(self, h, A, b, y):\n",
    "        \"\"\"\n",
    "        calculate cross entropy loss.\n",
    "        \"\"\"\n",
    "        s = np.dot(A, h) + b\n",
    "        p = self.sigmoid(s)\n",
    "        L = -y * np.log(p) - (1-y) * np.log(1- p) if s > 5 else (1 - y) * s\n",
    "        return L.astype(float)\n",
    "    \n",
    "    def update(self, t_hop, eps=0.001, alpha=0.0001):\n",
    "        \"\"\"\n",
    "        backward gradient to update params.\n",
    "        minimize Loss on each params; W, A, b.\n",
    "        \"\"\"\n",
    "        # For A\n",
    "        h = self.forward(t_hop, self.W, self.X)\n",
    "        A_deriv = []\n",
    "        for i in range(len(self.A)):\n",
    "            A_delta = self.A\n",
    "            A_delta[i] += eps\n",
    "            A_deriv.append((self.cross_entropy(h, A_delta, self.b, self.y) - self.cross_entropy(h, self.A, self.b, self.y))/eps)\n",
    "        # For b\n",
    "        b_deriv = (self.cross_entropy(h, self.A, self.b + eps, self.y) - self.cross_entropy(h, self.A, self.b, self.y))/eps\n",
    "\n",
    "        # For W\n",
    "        W_deriv = []\n",
    "        for i in range(len(self.W)):\n",
    "            temp = []\n",
    "            for j in range(len(self.W[i])):\n",
    "                W_delta = self.W\n",
    "                W_delta[i][j] += eps\n",
    "                temp.append((self.cross_entropy(self.forward(t_hop, W_delta, self.X), self.A, self.b, self.y) - self.cross_entropy(self.forward(t_hop, self.W, self.X), self.A, self.b, self.y))/eps)\n",
    "            W_deriv.append(temp)\n",
    "\n",
    "        # Update all parameters\n",
    "        A_new = self.A - np.dot(alpha, A_deriv)\n",
    "        b_new = self.b - alpha * b_deriv\n",
    "        W_new = self.W - np.dot(alpha, W_deriv)\n",
    "\n",
    "        return np.array(A_new), np.array(b_new), np.array(W_new)\n",
    "    \n",
    "    def train(self, t_hop=2, epoch=60, eps=0.001, alpha=0.0001):\n",
    "        \"\"\"\n",
    "        trainer. you can change iteration num.\n",
    "        \"\"\"\n",
    "        # start iteration\n",
    "        for i in range(epoch):\n",
    "            # update params\n",
    "            self.A, self.b, self.W = self.update(t_hop=t_hop, eps=eps, alpha=alpha)\n",
    "            # calculate and print loss to console\n",
    "            loss = self.cross_entropy(self.forward(t_hop, self.W, self.X), self.A, self.b, self.y)\n",
    "            print('epoch: {} loss: {}'.format(i + 1, loss))\n",
    "        \n",
    "    def predict(self, X, t_hop=2):\n",
    "        h = self.forward(t_hop, self.W, X)\n",
    "        s = np.dot(self.A, h) + b\n",
    "        p = 1. / (1. + np.exp(-s.astype(float)))\n",
    "        return int(p > 0.5)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnn = GNN(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1],\n",
       " [1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0]]"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnn.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnn.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 loss: -0.0\n",
      "epoch: 2 loss: -0.0\n",
      "epoch: 3 loss: -0.0\n",
      "epoch: 4 loss: -0.0\n",
      "epoch: 5 loss: -0.0\n",
      "epoch: 6 loss: -0.0\n",
      "epoch: 7 loss: -0.0\n",
      "epoch: 8 loss: -0.0\n",
      "epoch: 9 loss: -0.0\n",
      "epoch: 10 loss: -0.0\n"
     ]
    }
   ],
   "source": [
    "gnn.train(epoch=10, t_hop=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnn.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.37620284, -0.23141679,  0.47491807, -0.23056005, -0.62899426,\n",
       "         0.16909045,  0.49234617,  0.43251964,  0.35101756,  0.28575657,\n",
       "        -0.07989482],\n",
       "       [-0.19887287, -0.32602865,  0.48223325, -0.52153634, -0.0397587 ,\n",
       "        -0.18899256, -0.76884934, -0.72946199,  0.11586413,  0.38382872,\n",
       "        -0.45798573],\n",
       "       [ 0.30584216, -0.43486185, -0.78277078, -0.4675487 ,  0.07745058,\n",
       "        -0.82944517,  0.01766213,  0.13087429, -0.37415297,  0.64670524,\n",
       "         0.15093326],\n",
       "       [-0.25077836, -0.45480066, -0.90321503, -0.25509409, -0.09964819,\n",
       "         0.56030649, -0.06609325, -0.05302753, -0.54237418, -0.06386917,\n",
       "        -0.03166818],\n",
       "       [ 0.04378107,  0.31950413, -0.61996198, -0.55614755,  0.38225833,\n",
       "         0.16837289,  0.57879675, -0.97750256,  0.08975004, -0.47736443,\n",
       "        -0.28637057],\n",
       "       [ 0.43493536, -0.27566809,  0.75189257,  0.61983965, -0.70750143,\n",
       "        -0.24101194,  0.06203052,  0.69990144, -0.27048404,  0.06276348,\n",
       "        -0.67093228],\n",
       "       [-0.83230183,  0.30404877, -0.25823918, -0.05038639, -0.06995253,\n",
       "        -0.05315062,  0.61411704, -0.15884431,  0.32678999,  0.59927182,\n",
       "         0.35996724],\n",
       "       [-0.45966645,  0.2514381 , -0.32456342,  0.58439186,  0.64794975,\n",
       "         0.17053877,  0.7693401 ,  0.72354085,  0.58753115,  0.327522  ,\n",
       "        -0.1606227 ],\n",
       "       [-0.58273134,  0.15346496,  0.08522791,  0.38390431, -0.06236532,\n",
       "         0.3699513 ,  0.85820955,  0.37401147,  0.03136591,  0.07043161,\n",
       "        -0.58699989],\n",
       "       [-0.10511884, -0.1217139 ,  0.22347366,  0.11684919, -0.24167269,\n",
       "        -0.0336247 , -0.10841555,  0.39472538, -0.05479451,  0.67480382,\n",
       "        -0.19518535],\n",
       "       [-0.50359541, -0.89084576, -0.3389359 ,  0.40936477,  0.76395726,\n",
       "         0.38743673, -0.20727184,  0.10545474, -0.92589181,  0.05593589,\n",
       "        -0.77935678]])"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnn.W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.49383037,  0.14800578, -0.10842472,  0.55745151, -0.07370053,\n",
       "       -0.67744694,  0.45047784,  0.32676627,  0.19509685,  0.14105793,\n",
       "       -0.17839439])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnn.A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
